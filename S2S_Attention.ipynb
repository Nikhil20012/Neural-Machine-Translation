{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S2S-Attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZHchyZsjBT7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_RLojZVjFEx",
        "outputId": "3adacbf4-5032-4a22-e7f3-2e29b0acd859"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import string\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "L1ytiw1VjF57"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text(filename):\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "def to_lines(text):\n",
        "    sents = text.strip().split('\\n')\n",
        "    return sents\n",
        "text_hin=read_text('/content/drive/MyDrive/IITB.en-hi.hi')\n",
        "text_eng=read_text('/content/drive/MyDrive/IITB.en-hi.en')\n",
        "data_hin=to_lines(text_hin)#splitting into lines\n",
        "data_eng=to_lines(text_eng)\n",
        "#converting sentences to dataframe\n",
        "df_hin=pd.DataFrame(data_hin)\n",
        "df_eng=pd.DataFrame(data_eng)"
      ],
      "metadata": {
        "id": "A9wbfapnjckW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(data_eng,data_hin)))\n",
        "df.head(20)\n",
        "df.to_csv('/content/drive/MyDrive/dataset_tdl.csv')"
      ],
      "metadata": {
        "id": "7TTy5VQFjn8q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "2bA1CE_XjvdB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/dataset_tdl.csv\")\n",
        "data = data.head(25000)\n",
        "english_sentences = data[\"0\"]\n",
        "hindi_sentences = data[\"1\"]"
      ],
      "metadata": {
        "id": "cLl9jR5bkSTp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = 10000\n",
        "oov_token = '<UNK>'\n",
        "english_vocab_size = num_words + 1\n",
        "hindi_vocab_size = num_words + 1\n",
        "MAX_WORDS_IN_A_SENTENCE = 16\n",
        "test_ratio = 0.2\n",
        "BATCH_SIZE = 512\n",
        "embedding_dim = 64\n",
        "hidden_units = 1024\n",
        "learning_rate = 0.006\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "j8i8WD5dkasw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sen, is_english):\n",
        "\tif (type(sen) != str):\n",
        "\t\treturn ''\n",
        "\tsen = sen.strip('.')\n",
        "\t\n",
        "\t# insert space between words and punctuations\n",
        "\tsen = re.sub(r\"([?.!,¿;।])\", r\" \\1 \", sen)\n",
        "\tsen = re.sub(r'[\" \"]+', \" \", sen)\n",
        "\t\n",
        "\t# For english, replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n",
        "\tif(is_english == True):\n",
        "\t\tsen = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", sen)\n",
        "\t\tsen = sen.lower()\n",
        "\t\n",
        "\tsen = sen.strip()\n",
        "\tsen = 'sentencestart ' + sen + ' sentenceend'\n",
        "\t\n",
        "\tsen = ' '.join(sen.split())\n",
        "\treturn sen"
      ],
      "metadata": {
        "id": "ttvAgpG6kv_A"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each datapoint having english and hindi sentence\n",
        "processed_e_sentences = []\n",
        "processed_h_sentences = []\n",
        "for (e_sen, h_sen) in zip(english_sentences, hindi_sentences):\n",
        "\tprocessed_e_sen = preprocess_sentence(e_sen, True)\n",
        "\tprocessed_h_sen = preprocess_sentence(h_sen, False)\n",
        "\tif(processed_e_sen == '' or processed_h_sen == '' or processed_e_sen.count(' ') >  (MAX_WORDS_IN_A_SENTENCE-1) or processed_h_sen.count(' ') > (MAX_WORDS_IN_A_SENTENCE-1)):\n",
        "\t\tcontinue\n",
        "\t\n",
        "\tprocessed_e_sentences.append(processed_e_sen)\n",
        "\tprocessed_h_sentences.append(processed_h_sen)\n",
        "\n",
        "print(\"Sentence examples: \")\n",
        "print(processed_e_sentences[0])\n",
        "print(processed_h_sentences[0])\n",
        "print(\"Length of English processed sentences: \" + str(len(processed_e_sentences)))\n",
        "print(\"Length of Hindi processed sentences: \" + str(len(processed_h_sentences)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb6Oa1L2k6AM",
        "outputId": "28941e40-8f4c-4f0a-e15c-95b302ce8d5d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence examples: \n",
            "sentencestart give your application an accessibility workout sentenceend\n",
            "sentencestart अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें sentenceend\n",
            "Length of English processed sentences: 24178\n",
            "Length of Hindi processed sentences: 24178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentences(processed_sentences, num_words, oov_token):\n",
        "\ttokenizer = Tokenizer(num_words = num_words, oov_token = oov_token)\n",
        "\ttokenizer.fit_on_texts(processed_sentences)\n",
        "\tword_index = tokenizer.word_index\n",
        "\tsequences = tokenizer.texts_to_sequences(processed_sentences)\n",
        "\tsequences = pad_sequences(sequences, padding = 'post')\n",
        "\treturn word_index, sequences, tokenizer\n",
        "\n",
        "english_word_index, english_sequences, english_tokenizer = tokenize_sentences(processed_e_sentences, num_words, oov_token)\n",
        "hindi_word_index, hindi_sequences, hindi_tokenizer = tokenize_sentences(processed_h_sentences, num_words, oov_token)\n"
      ],
      "metadata": {
        "id": "s6ihjuZDk-gf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into traning and validation set\n",
        "english_train_sequences, english_val_sequences, hindi_train_sequences, hindi_val_sequences = train_test_split(english_sequences, hindi_sequences, test_size = test_ratio)\n",
        "BUFFER_SIZE = len(english_train_sequences)\n"
      ],
      "metadata": {
        "id": "qHQ7SkQElTXJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batching the training set\n",
        "dataset = tf.data.Dataset.from_tensor_slices((english_train_sequences, hindi_train_sequences)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
        "print(\"No. of batches: \" + str(len(list(dataset.as_numpy_iterator()))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82e7lfH1llhE",
        "outputId": "175f598d-6a26-4092-ad53-28626fd9c3e8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of batches: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "\t\n",
        "\tdef __init__(self, english_vocab_size, embedding_dim, hidden_units):\n",
        "\t\tsuper(Encoder, self).__init__()\n",
        "\t\tself.embedding = tf.keras.layers.Embedding(english_vocab_size, embedding_dim)\n",
        "\t\tself.gru = tf.keras.layers.GRU(hidden_units, return_sequences = True, return_state = True)\n",
        "\t\t\n",
        "\tdef call(self, input_sequence):\n",
        "\t\tx = self.embedding(input_sequence)\n",
        "\t\tencoder_sequence_output, final_encoder_state = self.gru(x)\n",
        "\t\t#\tDimensions of encoder_sequence_output => (BATCH_SIZE, MAX_WORDS_IN_A_SENTENCE, hidden_units)\n",
        "\t\t#\tDimensions of final_encoder_state => (BATCH_SIZE, hidden_units)\n",
        "\t\treturn encoder_sequence_output, final_encoder_state\n"
      ],
      "metadata": {
        "id": "OnpUCYcFlpCT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize our encoder\n",
        "encoder = Encoder(english_vocab_size, embedding_dim, hidden_units)\n",
        "\n",
        "class BasicDotProductAttention(tf.keras.layers.Layer):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(BasicDotProductAttention, self).__init__()\n",
        "\t\t\n",
        "\tdef call(self, decoder_hidden_state, encoder_outputs):\n",
        "\t\t#\tDimensions of decoder_hidden_state => (BATCH_SIZE, hidden_units)\n",
        "\t\t#\tDimensions of encoder_outputs => (BATCH_SIZE, MAX_WORDS_IN_A_SENTENCE, hidden_units)\n",
        "\n",
        "\t\tdecoder_hidden_state_with_time_axis = tf.expand_dims(decoder_hidden_state, 2)\n",
        "\t\t#\tDimensions of decoder_hidden_state_with_time_axis => (BATCH_SIZE, hidden_units, 1)\n",
        "\t\tattention_scores = tf.matmul(encoder_outputs, decoder_hidden_state_with_time_axis)\n",
        "\t\t#\tDimensions of attention_scores => (BATCH_SIZE, MAX_WORDS_IN_A_SENTENCE, 1)\n",
        "\t\tattention_scores = tf.nn.softmax(attention_scores, axis = 1)\n",
        "\t\tweighted_sum_of_encoder_outputs = tf.reduce_sum(encoder_outputs * attention_scores, axis = 1)\n",
        "\t\t#\tDimensions of weighted_sum_of_encoder_outputs => (BATCH_SIZE, hidden_units)\n",
        "\n",
        "\t\treturn weighted_sum_of_encoder_outputs, attention_scores\n"
      ],
      "metadata": {
        "id": "sfi_6_rklv_-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "\tdef __init__(self, hindi_vocab_size, embedding_dim, hidden_units):\n",
        "\t\tsuper(Decoder, self).__init__()\n",
        "\t\tself.embedding = tf.keras.layers.Embedding(hindi_vocab_size, embedding_dim)\n",
        "\t\tself.gru = tf.keras.layers.GRU(hidden_units, return_state = True)\n",
        "\t\tself.word_probability_layer = tf.keras.layers.Dense(hindi_vocab_size, activation = 'softmax')\n",
        "\t\tself.attention_layer = BasicDotProductAttention()\n",
        "\t\t\n",
        "\tdef call(self, decoder_input, decoder_hidden, encoder_sequence_output):\n",
        "\t\t\n",
        "\t\tx = self.embedding(decoder_input)\n",
        "\t\t#\tDimensions of x => (BATCH_SIZE, embedding_dim)\n",
        "\t\tweighted_sum_of_encoder_outputs, attention_scores = self.attention_layer(decoder_hidden, encoder_sequence_output)\n",
        "\t\t#\tDimensions of weighted_sum_of_encoder_outputs => (BATCH_SIZE, hidden_units)\n",
        "\t\tx = tf.concat([weighted_sum_of_encoder_outputs, x], axis = -1)\n",
        "\t\tx = tf.expand_dims(x, 1)\n",
        "\t\t#\tDimensions of x => (BATCH_SIZE, 1, hidden_units + embedding_dim)\n",
        "\t\tdecoder_output, decoder_state = self.gru(x)\n",
        "\t\t#\tDimensions of decoder_output => (BATCH_SIZE, hidden_units)\n",
        "\t\tword_probability = self.word_probability_layer(decoder_output)\n",
        "\t\t#\tDimensions of word_probability => (BATCH_SIZE, hindi_vocab_size)\n",
        "\t\treturn word_probability, decoder_state, attention_scores"
      ],
      "metadata": {
        "id": "0bhOppISly8L"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize our decoder\n",
        "decoder = Decoder(hindi_vocab_size, embedding_dim, hidden_units)\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
        "def loss_function(actual_words, predicted_words_probability):\n",
        "\tloss = loss_object(actual_words, predicted_words_probability)\n",
        "\tmask = tf.where(actual_words > 0, 1.0, 0.0)\n",
        "\treturn tf.reduce_mean(mask * loss)"
      ],
      "metadata": {
        "id": "D2w92RkLl9ZK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(english_sequences, hindi_sequences):\n",
        "\tloss = 0\n",
        "\twith tf.GradientTape() as tape:\n",
        "\t\tencoder_sequence_output, encoder_hidden = encoder(english_sequences)\n",
        "\t\tdecoder_hidden = encoder_hidden\n",
        "\t\tdecoder_input = hindi_sequences[:, 0]\n",
        "\t\tfor i in range(1, hindi_sequences.shape[1]):\n",
        "\t\t\tpredicted_words_probability, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_sequence_output)\n",
        "\t\t\tactual_words = hindi_sequences[:, i]\n",
        "\t\t\t# if all the sentences in batch are completed\n",
        "\t\t\tif np.count_nonzero(actual_words) == 0:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tloss += loss_function(actual_words, predicted_words_probability)\n",
        "\n",
        "\t\t\tdecoder_input = actual_words\n",
        "\n",
        "\tvariables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\tgradients = tape.gradient(loss, variables)\n",
        "\toptimizer.apply_gradients(zip(gradients, variables))\n",
        "\treturn loss.numpy()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rIKQj9SzmCJf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_epoch_losses = []\n",
        "training_start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "\tepoch_loss = []\n",
        "\tstart_time = time.time()\n",
        "\tfor(batch, (english_sequences, hindi_sequences)) in enumerate(dataset):\n",
        "\t\tbatch_loss = train_step(english_sequences, hindi_sequences)\n",
        "\t\tepoch_loss.append(batch_loss)\n",
        "\n",
        "\tall_epoch_losses.append(sum(epoch_loss)/len(epoch_loss))\n",
        "\tprint(\"Epoch No.: \" + str(epoch) + \" Time: \" + str(time.time()-start_time))\n",
        "\n",
        "print(\"All Epoch Losses: \" + str(all_epoch_losses))\n",
        "print(\"Total time in training: \" + str(time.time() - training_start_time))\n",
        "\n",
        "plt.plot(all_epoch_losses)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Epoch Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yahDHj5HmI-v",
        "outputId": "95be41f0-ee56-46cb-c369-e978bf83f9e2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch No.: 0 Time: 32.08095383644104\n",
            "Epoch No.: 1 Time: 30.827366828918457\n",
            "Epoch No.: 2 Time: 31.16741704940796\n",
            "Epoch No.: 3 Time: 30.794485330581665\n",
            "Epoch No.: 4 Time: 30.913137197494507\n",
            "Epoch No.: 5 Time: 30.466742753982544\n",
            "Epoch No.: 6 Time: 30.75901484489441\n",
            "Epoch No.: 7 Time: 40.95297312736511\n",
            "Epoch No.: 8 Time: 30.600569486618042\n",
            "Epoch No.: 9 Time: 30.606211185455322\n",
            "Epoch No.: 10 Time: 30.73444414138794\n",
            "Epoch No.: 11 Time: 30.485220432281494\n",
            "Epoch No.: 12 Time: 30.553207397460938\n",
            "Epoch No.: 13 Time: 30.632867336273193\n",
            "Epoch No.: 14 Time: 30.57555103302002\n",
            "Epoch No.: 15 Time: 30.59520959854126\n",
            "Epoch No.: 16 Time: 31.099153757095337\n",
            "Epoch No.: 17 Time: 30.682854652404785\n",
            "Epoch No.: 18 Time: 30.60259485244751\n",
            "Epoch No.: 19 Time: 30.715871572494507\n",
            "Epoch No.: 20 Time: 30.53346037864685\n",
            "Epoch No.: 21 Time: 30.495699644088745\n",
            "Epoch No.: 22 Time: 30.49625515937805\n",
            "Epoch No.: 23 Time: 31.005390405654907\n",
            "Epoch No.: 24 Time: 30.401612281799316\n",
            "Epoch No.: 25 Time: 30.66117548942566\n",
            "Epoch No.: 26 Time: 30.686053037643433\n",
            "Epoch No.: 27 Time: 30.680375337600708\n",
            "Epoch No.: 28 Time: 30.542665004730225\n",
            "Epoch No.: 29 Time: 30.58266568183899\n",
            "Epoch No.: 30 Time: 30.526902437210083\n",
            "Epoch No.: 31 Time: 30.34069323539734\n",
            "Epoch No.: 32 Time: 30.7114896774292\n",
            "Epoch No.: 33 Time: 30.770326614379883\n",
            "Epoch No.: 34 Time: 30.37968158721924\n",
            "Epoch No.: 35 Time: 30.55424404144287\n",
            "Epoch No.: 36 Time: 30.754538774490356\n",
            "Epoch No.: 37 Time: 30.74991536140442\n",
            "Epoch No.: 38 Time: 30.940632581710815\n",
            "Epoch No.: 39 Time: 30.73986840248108\n",
            "Epoch No.: 40 Time: 30.778746128082275\n",
            "Epoch No.: 41 Time: 30.621290922164917\n",
            "Epoch No.: 42 Time: 30.377251863479614\n",
            "Epoch No.: 43 Time: 30.85798168182373\n",
            "Epoch No.: 44 Time: 30.612006902694702\n",
            "Epoch No.: 45 Time: 30.957571983337402\n",
            "Epoch No.: 46 Time: 30.511870861053467\n",
            "Epoch No.: 47 Time: 30.678931951522827\n",
            "Epoch No.: 48 Time: 30.643028736114502\n",
            "Epoch No.: 49 Time: 30.671019554138184\n",
            "Epoch No.: 50 Time: 30.704051733016968\n",
            "Epoch No.: 51 Time: 30.61238718032837\n",
            "Epoch No.: 52 Time: 30.740383863449097\n",
            "Epoch No.: 53 Time: 30.811264753341675\n",
            "Epoch No.: 54 Time: 30.517897605895996\n",
            "Epoch No.: 55 Time: 30.700019598007202\n",
            "Epoch No.: 56 Time: 30.573982000350952\n",
            "Epoch No.: 57 Time: 30.405693769454956\n",
            "Epoch No.: 58 Time: 30.669594287872314\n",
            "Epoch No.: 59 Time: 30.740121841430664\n",
            "Epoch No.: 60 Time: 30.365774154663086\n",
            "Epoch No.: 61 Time: 40.952882528305054\n",
            "Epoch No.: 62 Time: 30.68674349784851\n",
            "Epoch No.: 63 Time: 30.818177461624146\n",
            "Epoch No.: 64 Time: 30.533129453659058\n",
            "Epoch No.: 65 Time: 30.701311826705933\n",
            "Epoch No.: 66 Time: 30.82301950454712\n",
            "Epoch No.: 67 Time: 30.773448944091797\n",
            "Epoch No.: 68 Time: 30.555074453353882\n",
            "Epoch No.: 69 Time: 30.671685934066772\n",
            "Epoch No.: 70 Time: 30.625380039215088\n",
            "Epoch No.: 71 Time: 30.50673246383667\n",
            "Epoch No.: 72 Time: 30.573745250701904\n",
            "Epoch No.: 73 Time: 30.755643367767334\n",
            "Epoch No.: 74 Time: 30.840243577957153\n",
            "Epoch No.: 75 Time: 30.503541946411133\n",
            "Epoch No.: 76 Time: 30.828263759613037\n",
            "Epoch No.: 77 Time: 30.531123161315918\n",
            "Epoch No.: 78 Time: 30.36137843132019\n",
            "Epoch No.: 79 Time: 30.18377685546875\n",
            "Epoch No.: 80 Time: 30.24572229385376\n",
            "Epoch No.: 81 Time: 30.64580798149109\n",
            "Epoch No.: 82 Time: 30.04211688041687\n",
            "Epoch No.: 83 Time: 30.57496166229248\n",
            "Epoch No.: 84 Time: 29.918678760528564\n",
            "Epoch No.: 85 Time: 30.39978051185608\n",
            "Epoch No.: 86 Time: 30.23241138458252\n",
            "Epoch No.: 87 Time: 30.29918336868286\n",
            "Epoch No.: 88 Time: 30.504276990890503\n",
            "Epoch No.: 89 Time: 30.200340270996094\n",
            "Epoch No.: 90 Time: 30.425586938858032\n",
            "Epoch No.: 91 Time: 30.176604509353638\n",
            "Epoch No.: 92 Time: 30.215553760528564\n",
            "Epoch No.: 93 Time: 30.243205547332764\n",
            "Epoch No.: 94 Time: 30.263546466827393\n",
            "Epoch No.: 95 Time: 30.421743869781494\n",
            "Epoch No.: 96 Time: 30.413305044174194\n",
            "Epoch No.: 97 Time: 30.29489827156067\n",
            "Epoch No.: 98 Time: 30.253146171569824\n",
            "Epoch No.: 99 Time: 30.352362871170044\n",
            "All Epoch Losses: [23.177386103449642, 18.359997440028835, 15.44448723664155, 12.515778412690034, 9.760944108705264, 7.446528666728252, 5.702817001858273, 4.498694142779788, 3.7641210556030273, 3.2859944717304126, 3.0078203678131104, 2.755708977982805, 2.6144077069050558, 2.5100855182957007, 2.454628886403264, 2.332271150640539, 2.22472696690946, 2.120873808860779, 2.0308607430071444, 1.953399023494205, 1.8916700369602926, 1.8243789350664295, 1.7996079051816785, 1.7473901413582467, 1.7141471521274463, 1.6428375276359353, 1.594278773745975, 1.5557495291168626, 1.5300412725757908, 1.5358596717989124, 1.4791395052059277, 1.4400341414116524, 1.4189809399682123, 1.408395757546296, 1.3527938997423328, 1.3356147940094407, 1.355617049578074, 1.3383823536537789, 1.375016969603461, 1.3750419777792853, 1.3411452158077344, 1.32459836070602, 1.282202427451675, 1.234995648667619, 1.1949672988943152, 1.2100280136675448, 1.1929403301831838, 1.1844552723137107, 1.209339715339042, 1.1701966846311413, 1.1316394354846027, 1.1267356840339866, 1.1125185103029818, 1.096631114547317, 1.1069180449923954, 1.1264064650277834, 1.1005762138882198, 1.1131242239797436, 1.0820124777587685, 1.0517827626821157, 1.0768080176533879, 1.08401180924596, 1.1299819301914524, 1.1106437654108614, 1.13645377352431, 1.1638048726159174, 1.1515209610397752, 1.115424025703121, 1.0404366721978058, 1.0043642182607908, 1.0312630485843968, 1.0844584655117344, 1.0182857690630733, 0.9762235219414169, 1.1049532986976005, 1.166738184722694, 1.2586149686091654, 1.6779955625534058, 16.3895757520521, 9.930710702329069, 5.725560768230541, 3.7612041202751367, 2.8183602771243534, 2.244308001286275, 1.8965484870446694, 1.7077549631531175, 1.5418398348060813, 1.43633251254623, 1.3262320724693504, 1.2569128371573783, 1.1856757354091954, 1.1568199267258514, 1.0964690446853638, 1.0750565287229177, 1.0311735949000798, 1.0149585572448936, 1.010476655251271, 0.9777114310780087, 0.971089868932157, 1.0156953576448802]\n",
            "Total time in training: 3080.3309984207153\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_from_sequences(sequences, tokenizer):\n",
        "\treturn tokenizer.sequences_to_texts(sequences)\n"
      ],
      "metadata": {
        "id": "3yL1bj58m0m6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "def translate_sentence(sentence):\n",
        "\tsentence = preprocess_sentence(sentence, True)\n",
        "\tsequence = english_tokenizer.texts_to_sequences([sentence])[0]\n",
        "\tsequence = tf.keras.preprocessing.sequence.pad_sequences([sequence], maxlen = MAX_WORDS_IN_A_SENTENCE, padding = 'post')\n",
        "\tencoder_input = tf.convert_to_tensor(sequence)\n",
        "\tencoder_sequence_output, encoder_hidden = encoder(encoder_input)\n",
        "\tdecoder_input = tf.convert_to_tensor([hindi_word_index['sentencestart']])\n",
        "\tdecoder_hidden = encoder_hidden\n",
        "\t\n",
        "\tsentence_end_word_id = hindi_word_index['sentenceend']\n",
        "\thindi_sequence = []\n",
        "\tfor i in range(MAX_WORDS_IN_A_SENTENCE*2):\n",
        "\t\tpredicted_words_probability, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_sequence_output)\n",
        "\t\t# taking the word with maximum probability\n",
        "\t\tpredicted_word_id = tf.argmax(predicted_words_probability[0]).numpy()\n",
        "\t\thindi_sequence.append(predicted_word_id)\n",
        "\t\t# if the word 'sentenceend' is predicted, exit the loop\n",
        "\t\tif predicted_word_id == sentence_end_word_id:\n",
        "\t\t\tbreak\n",
        "\t\tdecoder_input = tf.convert_to_tensor([predicted_word_id])\n",
        "\tprint(sentence)\n",
        "\treturn get_sentence_from_sequences([hindi_sequence], hindi_tokenizer)\n"
      ],
      "metadata": {
        "id": "pCtSOTSnwzTx"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print translated sentence\n",
        "print(translate_sentence(\"interactive console for manipulating currently selected accessible\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW6p14f6w2k1",
        "outputId": "5fc51e11-aee6-4eff-9ac9-2e5563479bc4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentencestart interactive console for manipulating currently selected accessible sentenceend\n",
            "['इस समय चुने गए एक्सेसेबेल से काम लेने के लिए अंतर्क्रियात्मक कन्सोल sentenceend']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BuKrVlN70btw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}